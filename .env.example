# grafeo-memory — Environment Variables
#
# Copy this file to .env and fill in the keys for your provider(s).
# Only the provider you use needs to be set.
#
# CLI usage:
#   grafeo-memory -m "mistral:mistral-small-latest" add "Alice works at Acme"
#   grafeo-memory -m "openai:gpt-4o-mini" --yolo search "Where does Alice work?"

# ── grafeo-memory config ────────────────────────────────────────────
# GRAFEO_MEMORY_MODEL=mistral:mistral-small-latest
# GRAFEO_MEMORY_DB=./memory.db
# GRAFEO_MEMORY_USER=default

# ── LLM Providers (pydantic-ai) ─────────────────────────────────────
# Pick one. The model string prefix determines which key is used.

# OpenAI              → openai:gpt-4o-mini, openai:gpt-4o
OPENAI_API_KEY=

# Anthropic           → anthropic:claude-sonnet-4-5-20250929
ANTHROPIC_API_KEY=

# Google (Gemini)     → google-gla:gemini-2.0-flash
GOOGLE_API_KEY=

# Mistral             → mistral:mistral-small-latest, mistral:mistral-large-latest
MISTRAL_API_KEY=

# Groq                → groq:llama-3.3-70b-versatile
GROQ_API_KEY=

# Cohere              → cohere:command-r-plus
CO_API_KEY=

# xAI (Grok)          → xai:grok-3-mini
XAI_API_KEY=

# DeepSeek            → deepseek:deepseek-chat
DEEPSEEK_API_KEY=

# Fireworks           → fireworks:accounts/fireworks/models/llama-v3p3-70b-instruct
FIREWORKS_API_KEY=

# Together            → together:meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
TOGETHER_API_KEY=

# Cerebras            → cerebras:llama-3.3-70b
CEREBRAS_API_KEY=

# OpenRouter          → openrouter:anthropic/claude-sonnet-4-5-20250929
OPENROUTER_API_KEY=

# ── Embedding Providers ─────────────────────────────────────────────
# The CLI auto-detects: mistral:* → MistralEmbedder, otherwise → OpenAIEmbedder.
# For the Python API you can use any EmbeddingClient implementation.

# OpenAI embeddings (used by default for non-Mistral models)
# OPENAI_API_KEY=  (same key as above)

# Mistral embeddings (used automatically when model is mistral:*)
# MISTRAL_API_KEY=  (same key as above)
